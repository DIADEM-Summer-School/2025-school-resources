{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAbRYZrtNSgH"
      },
      "source": [
        "# **From Classical Atoms to Machine Learning: A PhD-Level Introduction to Advanced Materials Simulation**\n",
        "\n",
        "This notebook provides a hands-on, pedagogical journey into the world of modern materials modeling, designed for PhD students and researchers entering the field. We will investigate the fascinating properties of **Aluminum (Al)**, a simple yet technologically vital metal. Our exploration will serve as a launchpad to understand and implement a powerful contemporary technique: **Machine Learning Interatomic Potentials (MLIPs)**.\n",
        "\n",
        "We will begin by generating a foundational dataset using a well-established classical method, the **Embedded Atom Method (EAM)**. This data will then become the training ground for a sophisticated neural network potential, utilizing the **n2p2 (short for \"neural network potential package\") code**. Finally, we'll validate our newly trained MLIP by comparing its predictions of a key structural property—the **radial distribution function (RDF)**—against the original EAM results.\n",
        "\n",
        "## **The Physical System: Aluminum and the Embedded Atom Method (EAM)**\n",
        "\n",
        "Aluminum, with its face-centered cubic (FCC) crystal structure, provides an ideal starting point for our investigation. To model the interactions between Al atoms, we will employ the Embedded Atom Method (EAM), a highly successful class of interatomic potentials for metallic systems.\n",
        "\n",
        "Unlike simple pairwise potentials that only consider the interaction between two atoms at a time, EAM is a many-body potential that captures a more realistic picture of metallic bonding. The core idea behind EAM is that the energy of an atom in a metal is determined by two main contributions:\n",
        "\n",
        "1.  **Pairwise Repulsion:** A standard two-body potential term that accounts for the electrostatic repulsion between atomic cores.\n",
        "2.  **Embedding Energy:** A many-body term that represents the energy required to \"embed\" an atom into the local electron density created by all its neighbors.\n",
        "\n",
        "The total energy *E* of the system in the EAM formalism is expressed as:\n",
        "\n",
        "$E = \\sum_i F_i(\\bar{\\rho}_i) + \\frac{1}{2} \\sum_{i \\ne j} \\phi_{ij}(r_{ij})$\n",
        "\n",
        "Where:\n",
        "\n",
        "*   $F_i(\\bar{\\rho}_i)$ is the **embedding energy** of atom *i* as a function of the local electron density $\\bar{\\rho}_i$.\n",
        "*   $\\bar{\\rho}_i = \\sum_{j \\ne i} \\rho_j(r_{ij})$ is the total electron density at the position of atom *i*, which is a sum of the contributions from its neighboring atoms *j*.\n",
        "*   $\\phi_{ij}(r_{ij})$ is the **pairwise potential** between atoms *i* and *j*, separated by a distance $r_{ij}$.\n",
        "\n",
        "This notebook utilizes a specific EAM potential for Aluminum developed by Zhakhovskii et al. (2009).\n",
        "\n",
        "## **Generating Training Data with Molecular Dynamics**\n",
        "\n",
        "The first crucial step in any machine learning endeavor is to acquire high-quality data. In our case, we will generate this data by performing a classical **Molecular Dynamics (MD)** simulation of bulk Aluminum using the LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) engine, accessed through the **Atomic Simulation Environment (ASE)**.\n",
        "\n",
        "Our simulation will involve a **temperature ramp**, where we gradually heat the system from a low temperature (100 K) to a high temperature (2000 K). This process allows us to sample a wide range of atomic configurations, from a well-ordered solid to a disordered liquid state. By doing so, we create a rich and diverse dataset that captures the material's behavior across different thermal conditions. This dataset, containing the positions, forces, and energies of all atoms at each step, will serve as the \"ground truth\" for training our MLIP. The use of machine learning to study phenomena like solidification in aluminum has been shown to be effective, reproducing structural and thermodynamic properties with near *ab initio* accuracy.\n",
        "\n",
        "## **Training a Machine Learning Interatomic Potential with n2p2**\n",
        "\n",
        "With our training data in hand, we now turn to the core of this tutorial: building a Machine Learning Interatomic Potential. We will use the **n2p2** code, a powerful and widely used software package for creating Behler-Parrinello type neural network potentials.\n",
        "\n",
        "The fundamental idea behind MLIPs is to use a flexible function, a neural network, to learn the complex relationship between the local atomic environment of an atom and its contribution to the total energy of the system. This approach moves beyond the predefined functional forms of classical potentials like EAM, allowing for a more accurate and transferable representation of the potential energy surface.\n",
        "\n",
        "The workflow for training our MLIP involves several key steps, all of which are implemented in this notebook:\n",
        "\n",
        "1.  **Data Conversion:** The trajectory data from our LAMMPS simulation is converted into the specific format required by n2p2.\n",
        "2.  **Feature Engineering:** To represent the atomic environments, n2p2 uses **atom-centered symmetry functions**. These functions describe the radial and angular distribution of neighboring atoms and are designed to be invariant to rotation, translation, and permutation of identical atoms, which are fundamental symmetries of physical systems.\n",
        "3.  **Scaling:** The input data is scaled to ensure numerical stability and efficient training of the neural network.\n",
        "4.  **Training:** The neural network is trained on the scaled data. The n2p2 code iteratively adjusts the weights and biases of the network to minimize the difference between the predicted and the actual energies and forces from our EAM-generated dataset. High-dimensional neural network potentials (HDNNPs) have evolved through several generations, continuously improving in their ability to handle large systems and complex interactions.\n",
        "5.  **Learning Curve Analysis:** We will plot the learning curve to monitor the training process. This plot shows how the error on the training and a separate testing dataset evolves over the training epochs, helping us to identify the optimal point to stop training and avoid overfitting.\n",
        "\n",
        "The broader context of this work lies in the growing synergy between machine learning and Density Functional Theory (DFT), where ML models are being developed to emulate DFT calculations at a fraction of the computational cost. This allows for the exploration of larger systems and longer timescales than would be possible with traditional *ab initio* methods. Such approaches are being used to predict a wide range of material properties, from electronic structure to mechanical stability in complex alloys like Ti-Nb and Ti-Zr.\n",
        "\n",
        "## **Validation: The Radial Distribution Function (RDF)**\n",
        "\n",
        "A crucial final step in developing any new potential is to validate its performance. We need to ensure that our trained MLIP can accurately reproduce the structural properties of the material. A powerful tool for this is the **Radial Distribution Function (RDF)**, denoted as g(r).\n",
        "\n",
        "The RDF describes the probability of finding a particle at a distance *r* from a reference particle, relative to the probability expected for a completely random distribution. It provides a detailed fingerprint of the local atomic structure.\n",
        "\n",
        "*   In a **solid**, the RDF exhibits sharp, well-defined peaks corresponding to the discrete shells of neighboring atoms in the crystal lattice.\n",
        "*   In a **liquid**, the RDF shows a few broad peaks at short distances, indicating short-range order, and then decays to unity at longer distances, reflecting the lack of long-range order.\n",
        "\n",
        "In this notebook, we will calculate and compare the RDFs produced by both the original EAM potential and our newly trained MLIP. By visualizing and analyzing these RDFs, we can quantitatively assess how well our machine-learned model has captured the essential physics of atomic interactions in Aluminum. A close agreement between the two RDFs will give us confidence in the predictive power of our MLIP for future, more complex simulations. The development of accurate and transferable MLIPs for metals like aluminum is an active area of research, with applications in understanding complex phenomena such as solidification and the properties of solid-liquid interfaces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGeUxHxN-XZ"
      },
      "source": [
        "# Souces for understand the notebook:\n",
        "**Core Concepts of Neural Network Potentials:**\n",
        "\n",
        "*   **Title:** Atom-centered symmetry functions for constructing high-dimensional neural network potentials\n",
        "    *   **Authors:** Jörg Behler\n",
        "    *   **Journal:** The Journal of Chemical Physics\n",
        "    *   **Link:** [https://aip.scitation.org/doi/10.1063/1.3553717](https://aip.scitation.org/doi/10.1063/1.3553717)\n",
        "    *   **Description:** This is the seminal paper that introduced the atom-centered symmetry functions used by n2p2 and many other modern machine learning potential frameworks. It is essential reading for understanding how atomic environments are described mathematically for the neural network.\n",
        "\n",
        "\n",
        "*   **Title:** Four Generations of High-Dimensional Neural Network Potentials\n",
        "    *   **Authors:** Jörg Behler\n",
        "    *   **Journal:** Chemical Reviews\n",
        "    *   **Link:** [https://pubs.acs.org/doi/10.1021/acs.chemrev.0c00868](https://pubs.acs.org/doi/10.1021/acs.chemrev.0c00868)\n",
        "    *   **Description:** This comprehensive review by one of the pioneers of the field describes the evolution of neural network potentials, their strengths, weaknesses, and future directions. It's an excellent resource for a deep dive into the methodology.\n",
        "\n",
        "**Application to Aluminum and Solidification:**\n",
        "\n",
        "\n",
        "*   **Title:** Machine learning interatomic potentials for aluminium: application to solidification phenomena\n",
        "    *   **Authors:** Noel Jakse & Alain Pasturel\n",
        "    *   **Journal:** Journal of Physics: Condensed Matter\n",
        "    *   **Link:** [https://doi.org/10.1088/1361-648X/ac9e2c](https://doi.org/10.1088/1361-648X/ac9e2c)\n",
        "    *   **Description:** This paper serves as a direct and practical application of the concepts discussed in the notebook. It demonstrates how a machine learning potential for aluminum can be used to accurately simulate the complex process of solidification, capturing key properties of both the solid and liquid phases. It's an excellent case study on the predictive power of MLIPs for real-world materials science problems.\n",
        "\n",
        "\n",
        "### **Annual Reviews (annualreviews.org)**\n",
        "\n",
        "*   **Title:** Machine Learning for Molecular Simulation\n",
        "    *   **Authors:** Frank C. Noé, Gianni De Fabritiis, and Cecilia Clementi\n",
        "    *   **Journal:** Annual Review of Physical Chemistry\n",
        "    *   **Link:** [https://www.annualreviews.org/doi/10.1146/annurev-physchem-042018-052331](https://www.annualreviews.org/doi/10.1146/annurev-physchem-042018-052331)\n",
        "    *   **Description:** This review covers the broader impact of machine learning on molecular simulation, including the construction of interatomic potentials and the analysis of simulation data to understand complex molecular processes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQaEgqOoWKca"
      },
      "source": [
        "Of course. Here is a comprehensive list of official documentation for the key software and Python libraries used in the notebook, formatted in Markdown for easy reference.\n",
        "\n",
        "### Software and Library Documentation\n",
        "\n",
        "#### **n2p2 (Neural Network Potential Package)**\n",
        "\n",
        "*   **Official Documentation:** [https://compphysvienna.github.io/n2p2/](https://compphysvienna.github.io/n2p2/)\n",
        "*   **Description:** The official user guide for n2p2. It contains detailed information on the installation process, the format of input files (like `input.nn` and `input.data`), how to run scaling and training tasks, and the theoretical background of the implemented neural network architecture.\n",
        "\n",
        "#### **LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator)**\n",
        "\n",
        "*   **Official Documentation:** [https://docs.lammps.org/](https://docs.lammps.org/)\n",
        "*   **Description:** The complete and authoritative manual for the LAMMPS molecular dynamics simulator. It is an essential resource for understanding the commands used in the input scripts (e.g., `pair_style`, `pair_coeff`, `fix nvt`), the theory behind the methods, and how to perform different types of simulations.\n",
        "\n",
        "#### **ASE (Atomic Simulation Environment)**\n",
        "\n",
        "*   **Official Documentation:** [https://wiki.fysik.dtu.dk/ase/](https://wiki.fysik.dtu.dk/ase/)\n",
        "*   **Description:** The official documentation for ASE, the Python library used to build atomic structures, interface with calculators like LAMMPS, and run dynamics. The documentation covers everything from creating `Atoms` objects to setting up calculators and analyzing simulation results.\n",
        "\n",
        "#### **OVITO (Open Visualization Tool)**\n",
        "\n",
        "*   **Official Documentation:** [https://www.ovito.org/docs/current/](https://www.ovito.org/docs/current/)\n",
        "*   **Description:** The user manual for OVITO, a powerful tool for the visualization and analysis of atomistic simulation data. The documentation details how to use its Python scripting interface (`ovito.io`, `ovito.modifiers`) to perform complex analyses, such as calculating the Radial Distribution Function (RDF) from a trajectory file.\n",
        "\n",
        "---\n",
        "\n",
        "### Python Library Documentation\n",
        "\n",
        "#### **Plotly**\n",
        "\n",
        "*   **Official Python Documentation:** [https://plotly.com/python/](https://plotly.com/python/)\n",
        "*   **Description:** The official documentation for the Plotly Python graphing library. It provides a comprehensive guide to creating a wide range of interactive figures, from basic scatter plots to complex animated visualizations. It's the go-to resource for understanding the `graph_objects` module used in the notebook.\n",
        "\n",
        "#### **NumPy**\n",
        "\n",
        "*   **Official Documentation:** [https://numpy.org/doc/stable/](https://numpy.org/doc/stable/)\n",
        "*   **Description:** The definitive user guide and API reference for NumPy, the fundamental package for scientific computing with Python. It provides detailed explanations of NumPy arrays (`ndarray`), mathematical functions, and the core routines used for numerical operations throughout the simulation workflow.\n",
        "\n",
        "#### **Pandas**\n",
        "\n",
        "*   **Official Documentation:** [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)\n",
        "*   **Description:** The official documentation for the Pandas library. It is the primary resource for learning how to use its powerful data structures, especially the `DataFrame`, for data manipulation and analysis. The guide explains functions like `pd.read_csv`, which is used in the notebook to parse the `learning-curve.out` file.\n",
        "\n",
        "#### **Pathlib (Path object)**\n",
        "\n",
        "*   **Official Python Documentation:** [https://docs.python.org/3/library/pathlib.html](https://docs.python.org/3/library/pathlib.html)\n",
        "*   **Description:** The official documentation for Python's `pathlib` module, which provides an object-oriented interface for handling filesystem paths. This is the modern and recommended way to manage file and directory paths in a way that is compatible across different operating systems (Windows, macOS, Linux)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTREU4zGCz4q"
      },
      "source": [
        "\n",
        "# Installation *section*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR6W5JhL8v2j",
        "outputId": "6bdc6488-99cc-4348-e8d3-b5d27ce3818f"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!ls\n",
        "!rm -rf input_data/ output_plot/ n2p2/ scaling/\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TN-Bq5wKDDMY"
      },
      "source": [
        "## Lammps and pytohn modules installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WYyoQp9-hhz",
        "outputId": "467933b4-6bd9-4043-cb6b-13413e104038"
      },
      "outputs": [],
      "source": [
        "# This cell aims to install LAMMPS and ASE. You can ignore the verbose outputs that come from it if you dont have any major error running it.\n",
        "%cd /content/\n",
        "!apt-get -qq update\n",
        "!pip --quiet install ase\n",
        "!pip --quiet install lammps==2024.8.29.3.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Uf5Idh8Cx3u"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82_kbuGgsIF1"
      },
      "source": [
        "# n2p2 Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_84JplmryE5",
        "outputId": "adab743f-babc-4312-e409-fcc68fdeb74f"
      },
      "outputs": [],
      "source": [
        "print(\"\\nCloning and compiling n2p2...\")\n",
        "## install lammp from n2p2 documentation I should work /bin/lmp_mpi\n",
        "## move your folder installation here!.'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS9w3UDnG0tv",
        "outputId": "45df7ed0-2a6a-46d4-fccf-95eac71418be"
      },
      "outputs": [],
      "source": [
        "!apt install build-essential libeigen3-dev libopenmpi-dev libblas-dev libgsl-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZssRcvCasU0u",
        "outputId": "127b5a10-4bc7-46b7-a128-dba931e2893a"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/CompPhysVienna/n2p2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ww61hSersdYZ",
        "outputId": "d60681cd-4670-43a6-f1b7-9886f81012bd"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D36zHYL9si_p",
        "outputId": "f450c02b-1e8c-4539-bb94-8bf1fa608d9c"
      },
      "outputs": [],
      "source": [
        "%cd /content/n2p2/src"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGHg42Muv-TJ"
      },
      "source": [
        "# Add n2p2 to the system path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YrF9nWOwCoC",
        "outputId": "558b6629-0048-4685-9582-19622655cb04"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PATH'] += \":/content/n2p2/bin\"\n",
        "print(\"n2p2 compiled.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPaIoBW9rWQz",
        "outputId": "b75c0f8f-58af-41b4-d6f7-1236b1dad134"
      },
      "outputs": [],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJpPH59KuVKS",
        "outputId": "9e648007-0404-4454-de1a-5f7ef0ad2d03"
      },
      "outputs": [],
      "source": [
        "%cd /content/n2p2/src\n",
        "!make MODE=shared libnnp\n",
        "!make MODE=shared libnnpif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_CBIGO0Fxeo",
        "outputId": "3a155cb4-5277-41ea-ef6b-6476300877f2"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzAWluzVFVw0",
        "outputId": "e9f9313a-5ee7-49eb-a747-9f3f94115f10"
      },
      "outputs": [],
      "source": [
        "%cd /content/n2p2/src\n",
        "!make MODE=shared nnp-scaling\n",
        "!make MODE=shared nnp-train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLGPfVs_YYgC",
        "outputId": "a079a7da-01ec-4a5f-f94b-e9e130632b58"
      },
      "outputs": [],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SF0HvmWtea4g",
        "outputId": "d3c42682-7116-4d4e-81fb-c9c9a6f957eb"
      },
      "outputs": [],
      "source": [
        "%cd /content/n2p2/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ4kPzTrKryR",
        "outputId": "e83a078f-c186-459b-ebb7-0629dbfefbb3"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZF9Ko_NZNQJ"
      },
      "source": [
        "# Data generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-26ELWouan2U"
      },
      "outputs": [],
      "source": [
        "# md_simulation_library.py\n",
        "import time\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from pathlib import Path # <-- Import the Path object\n",
        "import shutil # <-- Import shutil for efficient file copying\n",
        "\n",
        "# Importing ASE functionalities\n",
        "from ase import units\n",
        "from ase.build import bulk\n",
        "from ase.calculators.lammpslib import LAMMPSlib\n",
        "from ase.md.velocitydistribution import MaxwellBoltzmannDistribution, Stationary, ZeroRotation\n",
        "from ase.md.nvtberendsen import NVTBerendsen\n",
        "from ase.io import write\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-iVfZNHe6pH"
      },
      "source": [
        "## First, a \"simple\" MD to generete our input data\n",
        "As a first test case, we'll model **aluminium (Al)**, a widely used metal with a simple FCC (face-centered cubic) crystal structure that is easy to [build using ASE](https://wiki.fysik.dtu.dk/ase/ase/build/build.html). We'll perform a **temperature ramp simulation** of bulk aluminium using **periodic boundary conditions** to mimic an infinite crystal. Starting at a relatively low temperature (100 K), we will gradually increase the system temperature to 2000 K over 20,000 simulation steps. This controlled heating will help illustrate how thermal energy influences atomic motion and structure.\n",
        "\n",
        "In this exercise, we'll use a many-body empirical potential known as the **Embedded Atom Method (EAM)** to describe atomic interactions. The specific potential file used can be retrieved from [this link](https://www.ctcms.nist.gov/potentials/entry/2009--Zhakhovskii-V-V-Inogamov-N-A-Petrov-Y-V-et-al--Al/). EAM is an oldschool potential for modeling metallic systems, and even today it is widely used for its simplicity and well available parametrizations. It considers not only pairwise interactions between atoms but also the **embedding energy** associated with placing an atom into the local electron density generated by its neighbors. In this methodology, the total energy $E$ of a system of atoms is given by:\n",
        "\n",
        "$\n",
        "E = \\sum_i F_i(\\bar{\\rho}_i) + \\frac{1}{2} \\sum_{i \\ne j} \\phi_{ij}(r_{ij})\n",
        "$\n",
        "\n",
        "Where:\n",
        "- $F_i(\\rho_i)$ is the **embedding energy** for atom $i$, a function of the local electron density $\\rho_i$.\n",
        "- $\\bar{\\rho}_i = \\sum_{j \\ne i} \\rho_j(r_{i})$ is the local electron density at atom $i$ position, resulting from all neighboring atoms $j$.\n",
        "- $\\phi_{ij}(r_{ij})$ is a pairwise potential interaction between atoms $i$ and $j$.\n",
        "\n",
        "If you are interested in understanding it a little more, try to check [this reference](https://doi.org/10.1103/PhysRevB.29.6443) or [the EAM entry at LAMMPS manual](https://docs.lammps.org/pair_eam.html).\n",
        "\n",
        "\n",
        "Let's dive into the code and start building our MD script! Try to follow the comments and guide yourself through the code below. Once you're comfortable, get your hands dirty and try modifying the script. We've also included some challenges further down to help you test your understanding and progress."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzW03C9fcjPq"
      },
      "source": [
        "To generate the data I created 4 fucntions, you can include this 4 function into a specific file and named as md_simulation_library.py:\n",
        "\n",
        "1.   _download_potential_if_needed (The specific potential file)\n",
        "2.   setup_simulation (Definition of the superell and lammps calculator)\n",
        "3.   initialize_dynamics (define the initial conditions)\n",
        "4.   run_simulation_cycle (run the molecular dynamics simulation and returns the trajectory with position, forces and energies.)  \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cZR0lEXqa5aS"
      },
      "outputs": [],
      "source": [
        "def _download_potential_if_needed(filepath, url):\n",
        "    \"\"\"\n",
        "    Checks if a file exists and downloads it, adding a User-Agent header\n",
        "    to prevent HTTP 403 Forbidden errors.\n",
        "    \"\"\"\n",
        "    if not filepath.is_file():\n",
        "        print(f\"- Potential file '{filepath.name}' not found. Downloading...\")\n",
        "        try:\n",
        "            # Create a request object with a common browser User-Agent header\n",
        "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "            request = urllib.request.Request(url, headers=headers)\n",
        "\n",
        "            # Open the URL and save the content to the file\n",
        "            with urllib.request.urlopen(request) as response, open(filepath, 'wb') as out_file:\n",
        "                # Use shutil.copyfileobj to efficiently stream the download to the file\n",
        "                shutil.copyfileobj(response, out_file)\n",
        "\n",
        "            print(f\"- Download complete.\")\n",
        "        except urllib.error.HTTPError as e:\n",
        "            print(f\"Error: Could not download the potential file. The server returned an error.\")\n",
        "            print(f\"Details: {e}\")\n",
        "            raise FileNotFoundError(f\"Failed to download required potential file: {filepath}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during download: {e}\")\n",
        "            raise\n",
        "    else:\n",
        "        print(f\"- Potential file '{filepath.name}' found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPwsm1ofa8Q5"
      },
      "outputs": [],
      "source": [
        "def setup_simulation(potential_filepath, vscale):\n",
        "    \"\"\"\n",
        "    Sets up the atomic supercell and the LAMMPS calculator.\n",
        "    Accepts a pathlib.Path object for the potential file.\n",
        "    \"\"\"\n",
        "    potential_url = \"https://www.ctcms.nist.gov/potentials/Download/2009--Zhakhovskii-V-V-Inogamov-N-A-Petrov-Y-V-et-al--Al/2/Al-2009.eam.alloy\"\n",
        "\n",
        "    _download_potential_if_needed(potential_filepath, potential_url)\n",
        "\n",
        "    assert potential_filepath.is_file(), f\"Potential file is missing: {potential_filepath}!\"\n",
        "\n",
        "    atoms = bulk('Al', cubic=True, a=4.0495 * vscale**(1 / 3)).repeat((5, 5, 5))\n",
        "\n",
        "    lmp = LAMMPSlib(\n",
        "        lmpcmds=[\n",
        "            \"pair_style eam/alloy\",\n",
        "            f\"pair_coeff * * {str(potential_filepath)} Al\"\n",
        "        ],\n",
        "        atom_types={'Al': 1},\n",
        "        log_file=None,\n",
        "        keep_alive=True\n",
        "    )\n",
        "    atoms.calc = lmp\n",
        "    return atoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AkYpjbVbExq"
      },
      "outputs": [],
      "source": [
        "def initialize_dynamics(atoms, T_start, timestep_fs):\n",
        "    \"\"\"\n",
        "    Initializes velocities and creates the dynamics object.\n",
        "    \"\"\"\n",
        "    MaxwellBoltzmannDistribution(atoms, temperature_K=T_start)\n",
        "    ZeroRotation(atoms)\n",
        "    Stationary(atoms)\n",
        "    dyn = NVTBerendsen(\n",
        "        atoms,\n",
        "        timestep=timestep_fs * units.fs,\n",
        "        temperature_K=T_start,\n",
        "        taut=10 * units.fs\n",
        "    )\n",
        "    return dyn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctxkZXYdbI0j"
      },
      "outputs": [],
      "source": [
        "def run_simulation_cycle(dyn, atoms, n_steps, temperatures):\n",
        "    \"\"\"\n",
        "    Runs the molecular dynamics simulation cycle and collects the data.\n",
        "    \"\"\"\n",
        "    traj_data = []\n",
        "    def log_step():\n",
        "        step_idx = dyn.nsteps\n",
        "        if step_idx >= n_steps: return\n",
        "        T_current = temperatures[step_idx]\n",
        "        dyn.set_temperature(T_current)\n",
        "        traj_data.append({\n",
        "            \"step\": step_idx,\n",
        "            \"atoms\": atoms.copy(),\n",
        "            \"energy\": atoms.get_potential_energy(),\n",
        "            \"temperature\": atoms.get_temperature(),\n",
        "            \"forces\": atoms.get_forces()\n",
        "        })\n",
        "    dyn.attach(log_step, interval=1)\n",
        "    print(\"- Running MD...\")\n",
        "    dyn.run(n_steps)\n",
        "    return traj_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yadTHTC6biD4"
      },
      "source": [
        "## Convertion ase data format to n2p2 data format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVpluGDybpHV"
      },
      "outputs": [],
      "source": [
        "# n2p2_converter.py\n",
        "\n",
        "# ==============================================================================\n",
        "#  N2P2 DATA CONVERSION LIBRARY\n",
        "# ==============================================================================\n",
        "\n",
        "def _ase_to_n2p2_string(atoms_obj, energy, forces, step, temp):\n",
        "    \"\"\"\n",
        "    Converts a single ASE snapshot to the n2p2 string format.\n",
        "    (Internal function, prefixed with an underscore).\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    lines.append(\"begin\")\n",
        "    lines.append(f\"comment Step: {step}, Temp: {temp:.2f} K, Energy: {energy:.6f} eV\")\n",
        "    cell = atoms_obj.get_cell()\n",
        "    for i in range(3):\n",
        "        lines.append(f\"lattice {cell[i, 0]:.6f} {cell[i, 1]:.6f} {cell[i, 2]:.6f}\")\n",
        "\n",
        "    positions = atoms_obj.get_positions()\n",
        "    symbols = atoms_obj.get_chemical_symbols()\n",
        "    for i in range(len(atoms_obj)):\n",
        "        pos = positions[i]\n",
        "        sym = symbols[i]\n",
        "        f = forces[i]\n",
        "        line = (f\"atom {pos[0]:.6f} {pos[1]:.6f} {pos[2]:.6f} {sym} 0.0 0.0 \"\n",
        "                f\"{f[0]:.6f} {f[1]:.6f} {f[2]:.6f}\")\n",
        "        lines.append(line)\n",
        "\n",
        "    lines.append(f\"energy {energy:.6f}\")\n",
        "    lines.append(\"charge 0.0\")\n",
        "    lines.append(\"end\")\n",
        "    return \"\\n\".join(lines) + \"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJpNDrm-buUU"
      },
      "outputs": [],
      "source": [
        "def write_n2p2_data(traj_data, output_filename, sampling_rate):\n",
        "    \"\"\"\n",
        "    Converts trajectory data to n2p2 format and writes it to a file,\n",
        "    selecting one snapshot every `sampling_rate` steps.\n",
        "\n",
        "    Args:\n",
        "        traj_data (list): List of snapshot dictionaries from the simulation.\n",
        "        output_filename (str): The name of the file to save the data to.\n",
        "        sampling_rate (int): The interval for sampling snapshots.\n",
        "                             Defaults to 1 (write all snapshots).\n",
        "    \"\"\"\n",
        "    # Select the subset of snapshots using list slicing\n",
        "    sampled_traj = traj_data[::sampling_rate]\n",
        "\n",
        "    print(f\"\\n- Sampling 1 snapshot every {sampling_rate} steps...\")\n",
        "    print(f\"- Converting {len(sampled_traj)} of {len(traj_data)} total snapshots to n2p2 format...\")\n",
        "    print(f\"- Writing to file: {output_filename}\")\n",
        "\n",
        "    with open(output_filename, \"w\") as f:\n",
        "        # Iterate over the sampled list, not the full one\n",
        "        for snapshot in sampled_traj:\n",
        "            n2p2_str = _ase_to_n2p2_string(\n",
        "                atoms_obj=snapshot[\"atoms\"],\n",
        "                energy=snapshot[\"energy\"],\n",
        "                forces=snapshot[\"forces\"],\n",
        "                step=snapshot[\"step\"],\n",
        "                temp=snapshot[\"temperature\"]\n",
        "            )\n",
        "            f.write(n2p2_str)\n",
        "\n",
        "    print(f\"- Conversion complete. {len(sampled_traj)} structures written to {output_filename}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac4ru82Fgmw0"
      },
      "source": [
        "# How generate a small script to run a small workflow.\n",
        "To well organize all the fuctions togheter we still need some futher steps. Our main scripts need to get the parameters, need to know from which directory run it, where store inputs and outputs and a small workplow that generate our data\n",
        "1.   get_simulation_parameter (define the parameters)\n",
        "2.   create_directories (create inputs and outputs folders)\n",
        "3.   run_workflow (generate the data)\n",
        "4.   save results (write the resluls)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxJPLkUxgmaa"
      },
      "outputs": [],
      "source": [
        "def get_simulation_parameters():\n",
        "    \"\"\"\n",
        "    Defines and returns all simulation parameters using absolute paths.\n",
        "    \"\"\"\n",
        "    base_path = Path.cwd()\n",
        "\n",
        "    input_dir = base_path / \"input_data\"\n",
        "    plot_dir = base_path / \"output_plot\"\n",
        "    # Also define scaling and training dirs here for the check\n",
        "    scaling_dir = base_path / \"scaling\"\n",
        "    training_dir = base_path / \"training\"\n",
        "\n",
        "    params = {\n",
        "        # File paths\n",
        "        \"potential_filepath\": input_dir / \"Al-2009.eam.alloy\",\n",
        "        \"n2p2_output_filepath\": input_dir / \"input.data\",\n",
        "        \"plot_output_filepath\": plot_dir / \"potential_energy_plot.html\",\n",
        "        # Directories to create\n",
        "        \"directories\": [input_dir, plot_dir, scaling_dir, training_dir],\n",
        "        # Simulation parameters\n",
        "        \"T_start\": 100,\n",
        "        \"T_end\": 2000,\n",
        "        \"n_steps\": 20000,\n",
        "        \"timestep_fs\": 1.5,\n",
        "        \"vscale\": (2.697 / 2.304),\n",
        "        # NNP process parameters\n",
        "        \"scaling_processors\": 16,\n",
        "        \"training_processors\": 8,\n",
        "        # Workflow control\n",
        "        \"skip_nnp_if_exists\": True, # <-- NEW OPTION to control skipping behavior\n",
        "    }\n",
        "    return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYno-tO0m9Ci"
      },
      "outputs": [],
      "source": [
        "def create_directories(dir_paths):\n",
        "    \"\"\"Creates the necessary directories using pathlib if they don't exist.\"\"\"\n",
        "    print(\"- Checking and creating project directories...\")\n",
        "    for path in dir_paths:\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "    print(\"- Directory setup complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Dve-nyum_vw"
      },
      "outputs": [],
      "source": [
        "def run_workflow(params):\n",
        "    \"\"\"Executes the entire simulation workflow using the provided parameters.\"\"\"\n",
        "    atoms = setup_simulation(params[\"potential_filepath\"], params[\"vscale\"])\n",
        "    print(f\"- Setting up NVT temperature ramp from {params['T_start']} K to {params['T_end']} K over {params['n_steps']} steps...\")\n",
        "    dyn = initialize_dynamics(atoms, params[\"T_start\"], params[\"timestep_fs\"])\n",
        "    temperatures = np.linspace(params[\"T_start\"], params[\"T_end\"], params[\"n_steps\"])\n",
        "    traj_data = run_simulation_cycle(dyn, atoms, params[\"n_steps\"], temperatures)\n",
        "    return traj_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rO6l9yCnDUc"
      },
      "outputs": [],
      "source": [
        "def report_results(start_time, traj_data):\n",
        "    \"\"\"Prints a summary of the simulation results.\"\"\"\n",
        "    end_time = time.time()\n",
        "    #final_time =\n",
        "    print(f\"- MD finished. Total time: {(end_time - start_time)/60:.2f} s\")\n",
        "    print(f\"- Collected {len(traj_data)} snapshots.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Dc2gHK7-Tz2"
      },
      "outputs": [],
      "source": [
        "def save_trajectory_to_xyz(traj_data, output_dir, T_start, T_end, stride=100):\n",
        "    \"\"\"\n",
        "    Subsamples a trajectory and saves the atomic frames to an XYZ file.\n",
        "\n",
        "    Args:\n",
        "        traj_data (list): The full list of snapshots from the simulation.\n",
        "        output_dir (Path): The directory where the XYZ file will be saved.\n",
        "        T_start (int): The starting temperature, used for the filename.\n",
        "        T_end (int): The ending temperature, used for the filename.\n",
        "        stride (int): The interval for subsampling the trajectory.\n",
        "                      Defaults to 100.\n",
        "    \"\"\"\n",
        "    if not traj_data:\n",
        "        print(\"\\n- No trajectory data to save.\")\n",
        "        return\n",
        "\n",
        "    # 1. Define the output filename and construct the full path\n",
        "    xyz_filename = f\"traj_ramp_{T_start}K_to_{T_end}K.xyz\"\n",
        "    output_path = output_dir / xyz_filename\n",
        "\n",
        "    print(f\"\\n- Subsampling trajectory with a stride of {stride}...\")\n",
        "\n",
        "    # 2. Subsample the trajectory data by extracting the \"atoms\" object\n",
        "    #    from every Nth snapshot (where N = stride).\n",
        "    subsampled_frames = [\n",
        "        traj_data[i][\"atoms\"] for i in range(0, len(traj_data), stride)\n",
        "    ]\n",
        "\n",
        "    # 3. Write the collected frames to the XYZ file\n",
        "    write(output_path, subsampled_frames)\n",
        "\n",
        "    print(f\"- Subsampled trajectory with {len(subsampled_frames)} frames saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IcLIs5ZoHhz"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjY4Ek2FoGB-"
      },
      "outputs": [],
      "source": [
        "# plot_results.py\n",
        "\n",
        "# ==============================================================================\n",
        "#  SIMULATION RESULTS - VISUALIZATION\n",
        "# ==============================================================================\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_potential_energy(traj_data, output_filename=\"potential_energy_plot.html\"):\n",
        "    \"\"\"\n",
        "    Creates an interactive plot of the potential energy from the\n",
        "    simulation trajectory and saves it to an HTML file.\n",
        "\n",
        "    Args:\n",
        "        traj_data (list): A list of snapshots from the simulation.\n",
        "        output_filename (str): The name of the output HTML file.\n",
        "    \"\"\"\n",
        "    if not traj_data:\n",
        "        print(\"\\n- No trajectory data to plot.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n- Generating the potential energy plot...\")\n",
        "\n",
        "    # 1. Extract data from the trajectory\n",
        "    steps = [snapshot['step'] for snapshot in traj_data]\n",
        "    energies = [snapshot['energy'] for snapshot in traj_data]\n",
        "\n",
        "    # 2. Create a standard figure object\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # 3. Add the trace for Potential Energy\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=steps,\n",
        "            y=energies,\n",
        "            name='Potential Energy',\n",
        "            mode='lines',\n",
        "            marker_color='royalblue'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # 4. Update the layout (titles, labels, etc.)\n",
        "    fig.update_layout(\n",
        "        title_text='<b>Potential Energy Evolution During Simulation</b>',\n",
        "        title_x=0.5,\n",
        "        xaxis_title='Simulation Step',\n",
        "        yaxis_title='<b>Potential Energy (eV)</b>',\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    # 5. Save the plot to an HTML file\n",
        "    fig.write_html(output_filename)\n",
        "    print(f\"- Plot successfully saved to: {output_filename}\")\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnAnULnPnGuh"
      },
      "source": [
        "# Script--> workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs6Kf-Y7p0xs"
      },
      "outputs": [],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-gVy3Eg_bF2"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pL3lRE8AnFl2"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "simulation_params = get_simulation_parameters()\n",
        "create_directories(simulation_params[\"directories\"])\n",
        "\n",
        "trajectory_data = run_workflow(simulation_params)\n",
        "report_results(t0, trajectory_data)\n",
        "\n",
        "if trajectory_data:\n",
        "        xyz_output_dir = simulation_params[\"n2p2_output_filepath\"].parent\n",
        "        save_trajectory_to_xyz(\n",
        "            trajectory_data,\n",
        "            xyz_output_dir,\n",
        "            simulation_params[\"T_start\"],\n",
        "            simulation_params[\"T_end\"]\n",
        "        )\n",
        "\n",
        "        write_n2p2_data(trajectory_data, simulation_params[\"n2p2_output_filepath\"], sampling_rate=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V5oCEocCNrQ"
      },
      "outputs": [],
      "source": [
        "%cd /content/input_data\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0BdsRWgZY6Q"
      },
      "source": [
        "# Scaling data\n",
        "Upload input.nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lv_IjLl3vP6j"
      },
      "outputs": [],
      "source": [
        "%cd /content/scaling\n",
        "!ln -s /content/input_data/input.nn .\n",
        "!ln -s /content/input_data/input.data .\n",
        "%cd /content/scaling\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d80c4931"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if 'LD_LIBRARY_PATH' in os.environ:\n",
        "    os.environ['LD_LIBRARY_PATH'] += \":/content/n2p2/lib\"\n",
        "else:\n",
        "    os.environ['LD_LIBRARY_PATH'] = \"/content/n2p2/lib\"\n",
        "print(\"✅ LD_LIBRARY_PATH updated.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb9023ec"
      },
      "outputs": [],
      "source": [
        "!OMPI_ALLOW_RUN_AS_ROOT=1 OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 mpirun -np 1 /content/n2p2/bin/nnp-scaling 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "He3aUltYcsGw"
      },
      "outputs": [],
      "source": [
        "#run if you re-do the scaling\n",
        "%cd /content/scaling/\n",
        "!ls\n",
        "!OMPI_ALLOW_RUN_AS_ROOT=1 OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 mpirun -np 32 /content/n2p2/bin/nnp-scaling 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWuDaz5kdUmr"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfYJfqIvZY1b"
      },
      "source": [
        "# Training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi6Ui3Hlwn1C"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!ls\n",
        "!rm -rf /content/training\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db0d13aa"
      },
      "outputs": [],
      "source": [
        "%cd /content/training/\n",
        "!ln -s /content/scaling//input.data .\n",
        "!ln -s /content/scaling//input.nn .\n",
        "!ln -s /content/scaling//scaling.data .\n",
        "!OMPI_ALLOW_RUN_AS_ROOT=1 OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 mpirun -np 1 /content/n2p2/bin/nnp-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yKUOE54ddJ6"
      },
      "outputs": [],
      "source": [
        "#run if you re-do the traing\n",
        "%cd ../train_data\n",
        "!ls\n",
        "!rm *\n",
        "!ls\n",
        "!ln -s /content/scaling/input.data .\n",
        "!ln -s /content/scaling/input.nn .\n",
        "!ln -s /content/scaling/scaling.data .\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9684b6c"
      },
      "outputs": [],
      "source": [
        "%cd /content/train_data/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkK4nM8ZZm1U"
      },
      "source": [
        "# Best epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYFWamglbLMr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRxk6aAgWESZ"
      },
      "outputs": [],
      "source": [
        "# plot_learning_curve.py\n",
        "\n",
        "def load_and_plot_learning_curve(file_path: Path, output_dir: Path, ignore_initial_epochs: int = 100, y_min=0.007, y_max=0.013) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Loads learning curve data, plots it, calculates minimum RMSE after a\n",
        "    certain number of epochs, and saves the plot as an HTML file.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the 'learning-curve*.out' file.\n",
        "        output_dir: Directory to save the plot.\n",
        "        ignore_initial_epochs: Number of initial epochs to ignore when finding the minimum RMSE.\n",
        "        y_min: Minimum y-axis limit (currently not used in log scale).\n",
        "        y_max: Maximum y-axis limit (currently not used in log scale).\n",
        "\n",
        "    Returns:\n",
        "        A pandas DataFrame containing the loaded data.\n",
        "    \"\"\"\n",
        "    # Read the file to find the header row\n",
        "    with file_path.open(\"r\") as f:\n",
        "        for line in f:\n",
        "            if line.lower().startswith(\"#    epoch\"):\n",
        "                header_line = line\n",
        "                break\n",
        "        else:\n",
        "            raise ValueError(f\"Header row not found in {file_path.name}\")\n",
        "\n",
        "    # Clean up the header\n",
        "    header_line = header_line.strip(\"#\").strip()\n",
        "    column_names = header_line.split()\n",
        "\n",
        "    # Read the data, ignoring comment lines\n",
        "    data = pd.read_csv(file_path, delim_whitespace=True, comment=\"#\", header=None)\n",
        "\n",
        "    if len(column_names) != data.shape[1]:\n",
        "        raise ValueError(\n",
        "            f\"Mismatch between number of columns ({len(column_names)}) and read columns ({data.shape[1]})\"\n",
        "        )\n",
        "    data.columns = column_names\n",
        "\n",
        "    print(f\"\\n- Columns read from {file_path.name}: {data.columns.tolist()}\")\n",
        "\n",
        "    # Create a sliced DataFrame for calculating the minimum, ignoring initial epochs\n",
        "    if len(data) > ignore_initial_epochs:\n",
        "        data_for_min_calc = data.iloc[ignore_initial_epochs:]\n",
        "    else:\n",
        "        data_for_min_calc = data # Not enough data to ignore, use all of it\n",
        "\n",
        "    # Create a Plotly figure\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Plot RMSEpa_Etrain_pu and find its minimum\n",
        "    if \"RMSEpa_Etrain_pu\" in data.columns:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=data[\"epoch\"],\n",
        "            y=data[\"RMSEpa_Etrain_pu\"],\n",
        "            mode='lines',\n",
        "            name=\"Train RMSE/atom\"\n",
        "        ))\n",
        "        if not data_for_min_calc.empty:\n",
        "            min_val = data_for_min_calc[\"RMSEpa_Etrain_pu\"].min()\n",
        "            min_epoch = data_for_min_calc.loc[data_for_min_calc[\"RMSEpa_Etrain_pu\"].idxmin(), \"epoch\"]\n",
        "            print(f\"  - Min Train RMSE/atom (after epoch {ignore_initial_epochs}): {min_val:.6f} at epoch {min_epoch}\")\n",
        "\n",
        "    # Plot RMSEpa_Etest_pu and find its minimum\n",
        "    if \"RMSEpa_Etest_pu\" in data.columns:\n",
        "        fig.add_trace(go.Scatter(\n",
        "            x=data[\"epoch\"],\n",
        "            y=data[\"RMSEpa_Etest_pu\"],\n",
        "            mode='lines',\n",
        "            name=\"Test RMSE/atom\"\n",
        "        ))\n",
        "        if not data_for_min_calc.empty:\n",
        "            min_val = data_for_min_calc[\"RMSEpa_Etest_pu\"].min()\n",
        "            min_epoch = data_for_min_calc.loc[data_for_min_calc[\"RMSEpa_Etest_pu\"].idxmin(), \"epoch\"]\n",
        "            print(f\"  - Min Test RMSE/atom (after epoch {ignore_initial_epochs}): {min_val:.6f} at epoch {min_epoch}\")\n",
        "\n",
        "    # Update layout for title, labels, and scales\n",
        "    fig.update_layout(\n",
        "        title=f\"Learning Curve - {file_path.stem}\",\n",
        "        xaxis_title=\"Epoch\",\n",
        "        yaxis_title=\"RMSE (physical units)\",\n",
        "        yaxis_type=\"log\",\n",
        "        legend_title=\"Legend\",\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "\n",
        "    # Save the plot as an interactive HTML file\n",
        "    output_file = output_dir / (file_path.stem + \".html\")\n",
        "    fig.write_html(output_file)\n",
        "    print(f\"- Learning curve plot saved to: {output_file}\")\n",
        "\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6cXNDFOXZAE"
      },
      "outputs": [],
      "source": [
        "# The code within the if __name__ == '__main__': block is not needed in Colab.\n",
        "# The function load_and_plot_learning_curve will be called directly.\n",
        "# Define the paths based on the simulation parameters or other means if needed.\n",
        "# Example:\n",
        "# learning_curve_file = Path(\"/content/train_data/learning-curve.out\")\n",
        "# plot_output_dir = Path(\"/content/train_data/best_epochs\")\n",
        "# load_and_plot_learning_curve(learning_curve_file, plot_output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbaYj6aswC-x"
      },
      "outputs": [],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQkDqAt4b53z"
      },
      "outputs": [],
      "source": [
        "#for the student with 1000 epochs\n",
        "learning_curve_file = Path(\"/content/training/learning-curve.out\")\n",
        "plot_output_dir = Path(\"/content/output_plot/\")\n",
        "load_and_plot_learning_curve(learning_curve_file, plot_output_dir, ignore_initial_epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z6Kb8Zo3qQj"
      },
      "outputs": [],
      "source": [
        "#learnig curve 10000 epochs\n",
        "learning_curve_file = Path(\"/content/drive/MyDrive/A_data_summer_school_25/learning-curve.out\")\n",
        "plot_output_dir = Path(\"/content/output_plot/\")\n",
        "load_and_plot_learning_curve(learning_curve_file, plot_output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4el1drxWLe3"
      },
      "outputs": [],
      "source": [
        "# The code within this block is only needed when running as a standalone script.\n",
        "# In Colab, you can call the functions directly with the appropriate paths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UZrMKwIZYwW"
      },
      "source": [
        "# Validation procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mma7mPiyeyI_"
      },
      "source": [
        "To validate our mlip procedure we will use lammps software.\n",
        "To run a calculation in lammps we need some input files:\n",
        "-\n",
        "\n",
        "1.   scaling.data which we obtained run the scaling\n",
        "2.   in.lmp (a script that contains all initial parameters and how you want do your calculation)\n",
        "3.   INtest.data a initial stucture to lunch the simulation\n",
        "4.   the best test weights obtained during the training\n",
        "\n",
        "To create the INtest we just copy one of the 200 structures into a file 222_IN.data and then we convert this data n2p2 format into xyz format readble by lammps software"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZk1GDrvYLL5"
      },
      "source": [
        "### Access to lammps executable https://drive.google.com/drive/folders/1PZRPBGXmJEiKcXhBxZVRe3njrFmndxE6?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIXz9hFHguba"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Validation_lammps_calculation/A_students\n",
        "!ls\n",
        "!cp /content/drive/MyDrive/Validation_lammps_calculation/scaling.data .\n",
        "!cp /content/drive/MyDrive/Validation_lammps_calculation/222_IN.data .\n",
        "!cp /content/drive/MyDrive/Validation_lammps_calculation/in.lmp .\n",
        "!cp /content/drive/MyDrive/Validation_lammps_calculation/weights.013.data .\n",
        "!cp /content/input_data/input.nn .\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBOhoJS0Z471"
      },
      "outputs": [],
      "source": [
        "# data_converter.py\n",
        "\n",
        "def convert_n2p2_to_lammps_data(input_path: Path, output_path: Path):\n",
        "    \"\"\"\n",
        "    Reads an n2p2-style data file and converts it into a LAMMPS data file format.\n",
        "\n",
        "    Args:\n",
        "        input_path (Path): The path to the input n2p2 data file.\n",
        "        output_path (Path): The path where the output LAMMPS data file will be saved.\n",
        "    \"\"\"\n",
        "    atoms = []\n",
        "    # Initialize a placeholder for the simulation box vectors\n",
        "    box_vectors = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
        "    lattice_lines_read = 0\n",
        "\n",
        "    # Ensure the input file exists before proceeding\n",
        "    if not input_path.is_file():\n",
        "        raise FileNotFoundError(f\"Input file not found at: {input_path}\")\n",
        "\n",
        "    with input_path.open('r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Parse the n2p2 input file\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line.startswith('lattice'):\n",
        "            parts = line.split()\n",
        "            if lattice_lines_read < 3:\n",
        "                # Store the full lattice vectors\n",
        "                box_vectors[lattice_lines_read] = [float(parts[i]) for i in range(1, 4)]\n",
        "                lattice_lines_read += 1\n",
        "        elif line.startswith('atom'):\n",
        "            parts = line.split()\n",
        "            x, y, z = map(float, parts[1:4])\n",
        "            element = parts[4]\n",
        "            atoms.append((element, x, y, z))\n",
        "\n",
        "    # Determine simulation box boundaries from the vectors\n",
        "    xhi = box_vectors[0][0]\n",
        "    yhi = box_vectors[1][1]\n",
        "    zhi = box_vectors[2][2]\n",
        "\n",
        "    unique_elements = sorted(list(set(atom[0] for atom in atoms)))\n",
        "\n",
        "    # Write the LAMMPS data file\n",
        "    with output_path.open('w') as f:\n",
        "        # Header section\n",
        "        f.write(f\"LAMMPS data file generated from {input_path.name}\\n\\n\")\n",
        "        f.write(f\"{len(atoms)} atoms\\n\")\n",
        "        f.write(f\"{len(unique_elements)} atom types\\n\\n\")\n",
        "\n",
        "        # Box dimensions section\n",
        "        f.write(f\"0.0 {xhi:.6f} xlo xhi\\n\")\n",
        "        f.write(f\"0.0 {yhi:.6f} ylo yhi\\n\")\n",
        "        f.write(f\"0.0 {zhi:.6f} zlo zhi\\n\\n\")\n",
        "\n",
        "        # Masses section\n",
        "        f.write(\"Masses\\n\\n\")\n",
        "        for idx, element in enumerate(unique_elements, 1):\n",
        "            # Using a placeholder mass. This should be adjusted for real simulations.\n",
        "            f.write(f\"{idx} 1.0  # {element}\\n\")\n",
        "\n",
        "        # Atoms section\n",
        "        f.write(\"\\nAtoms\\n\\n\")\n",
        "        atom_id = 1\n",
        "        for element, x, y, z in atoms:\n",
        "            atom_type = unique_elements.index(element) + 1\n",
        "            f.write(f\"{atom_id} {atom_type} {x:.6f} {y:.6f} {z:.6f}\\n\")\n",
        "            atom_id += 1\n",
        "\n",
        "    print(f\"Converted {len(atoms)} atoms to LAMMPS data format in '{output_path}'\")\n",
        "\n",
        "# This block allows the script to be run directly for testing purposes\n",
        "if __name__ == '__main__':\n",
        "    # --- Example of how to use the function ---\n",
        "\n",
        "    # 1. Define the input and output file paths using pathlib\n",
        "    #    You would change these to your actual file names.\n",
        "    input_file = Path('222_IN.data')\n",
        "    output_file = Path('INtest.data')\n",
        "\n",
        "    # 2. Call the conversion function\n",
        "    try:\n",
        "        convert_n2p2_to_lammps_data(input_file, output_file)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"Please make sure the input file exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAiT6MjjgjGq"
      },
      "outputs": [],
      "source": [
        "input_file = Path('/content/drive/MyDrive/A_lammps_n2p2_calculation/A_students/222_IN.data')\n",
        "output_file = Path('/content/drive/MyDrive/A_lammps_n2p2_calculation/A_students/INtest.data')\n",
        "convert_n2p2_to_lammps_data(input_file, output_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE2EprnjZYpt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_husybgdofe"
      },
      "outputs": [],
      "source": [
        "# change permission into my files\n",
        "%cd /content/drive/MyDrive/Validation_lammps_calculation\n",
        "!ls\n",
        "!chmod +x lmp_mpi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snq5M3ibbE4X"
      },
      "source": [
        "LAMMPS lmp_mpi called from n2p2 folder irinapiazza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJYGx7ltbM6X"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Validation_lammps_calculation/\n",
        "!ls\n",
        "!OMPI_ALLOW_RUN_AS_ROOT=1 OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 mpirun -n 1 /content/drive/MyDrive/Validation_lammps_calculation/lmp_mpi -in in.lmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UElwAg6Vjc-2",
        "outputId": "54636a0e-c4f4-4190-9297-c4aa981989c7"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Validation_lammps_calculation/\n",
        "!ls\n",
        "!chmod +x lmp_mpi\n",
        "!OMPI_ALLOW_RUN_AS_ROOT=1 OMPI_ALLOW_RUN_AS_ROOT_CONFIRM=1 mpirun -n 1 /content/drive/MyDrive/Validation_lammps_calculation/lmp_mpi -in in_test.lmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l_yiN4USQBO",
        "outputId": "5d745b2d-4730-4258-9b83-1998206b7c6a"
      },
      "outputs": [],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auz1I8Y_3M8X",
        "outputId": "db0c337f-9d60-432a-e411-6d06def2185c"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install the necessary libraries\n",
        "!pip install -qU ovito numpy plotly\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjgdVtyNvid0"
      },
      "source": [
        "# Radial distribution function comparison between mlip methon and classical eam potential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mkE1O9EH3ZPv"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries (should be at the top of your script)\n",
        "import ovito.io\n",
        "from ovito.modifiers import CoordinationAnalysisModifier\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yv7ZgyrC34UW"
      },
      "outputs": [],
      "source": [
        "def generate_rdf_animation(file_path: str,\n",
        "                           output_filename: str = 'rdf_animation.html',\n",
        "                           cutoff_radius: float = 8.0,\n",
        "                           number_of_bins: int = 150,\n",
        "                           frame_duration: int = 100):\n",
        "    \"\"\"\n",
        "    Calculates and visualizes an animation of the Radial Distribution Function (RDF)\n",
        "    from a trajectory file and saves it as an interactive HTML file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The full path to the trajectory file (e.g., .lammpstrj).\n",
        "        output_filename (str, optional): The name for the output HTML file.\n",
        "                                         Defaults to 'rdf_animation.html'.\n",
        "        cutoff_radius (float, optional): The maximum cutoff radius in Angstroms for the\n",
        "                                         RDF calculation. Defaults to 8.0.\n",
        "        number_of_bins (int, optional): The number of bins for the RDF histogram.\n",
        "                                        Defaults to 150.\n",
        "        frame_duration (int, optional): The duration of each frame in the animation in\n",
        "                                        milliseconds. Defaults to 100.\n",
        "\n",
        "    Returns:\n",
        "        go.Figure: The Plotly Figure object containing the animation.\n",
        "                   Returns None if no valid RDF data is found.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Load data and set up the OVITO pipeline ---\n",
        "    print(f\"Loading file: {file_path}\")\n",
        "    try:\n",
        "        pipeline = ovito.io.import_file(file_path, multiple_frames=True)\n",
        "        num_frames = pipeline.source.num_frames\n",
        "        if num_frames == 0:\n",
        "            print(\"Error: OVITO found no frames in the file.\")\n",
        "            return None\n",
        "        print(f\"Found {num_frames} frames in the trajectory.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error while loading file with OVITO: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Add the modifier to calculate the RDF\n",
        "    rdf_modifier = CoordinationAnalysisModifier(\n",
        "        cutoff=cutoff_radius,\n",
        "        number_of_bins=number_of_bins\n",
        "    )\n",
        "    pipeline.modifiers.append(rdf_modifier)\n",
        "\n",
        "    # --- Pre-calculate the RDF for all frames ---\n",
        "    all_rdf_data = []\n",
        "    print(\"Calculating RDF for all frames...\")\n",
        "    for frame_index in range(num_frames):\n",
        "        data = pipeline.compute(frame_index)\n",
        "        if 'coordination-rdf' in data.tables and data.tables['coordination-rdf'].y is not None:\n",
        "            rdf_table = data.tables['coordination-rdf']\n",
        "            frame_data = {'x': rdf_table.xy()[:, 0], 'y': rdf_table.xy()[:, 1], 'original_frame': frame_index}\n",
        "            all_rdf_data.append(frame_data)\n",
        "        else:\n",
        "            # Add a placeholder to maintain index correspondence if needed\n",
        "            all_rdf_data.append(None)\n",
        "\n",
        "        if (frame_index + 1) % 50 == 0 or frame_index == num_frames - 1:\n",
        "            print(f\"  Processed frame {frame_index + 1}/{num_frames}\")\n",
        "\n",
        "    # --- Filter data and create the plot ---\n",
        "    valid_rdf_data = [rdf for rdf in all_rdf_data if rdf is not None and len(rdf['x']) > 0]\n",
        "\n",
        "    if not valid_rdf_data:\n",
        "        print(\"Error: No valid RDF data was collected from the trajectory.\")\n",
        "        return None\n",
        "\n",
        "    print(\"RDF calculation complete. Building interactive plot...\")\n",
        "\n",
        "    # Find the max y-value to set the axis range dynamically\n",
        "    max_y_value = max(np.max(rdf['y']) for rdf in valid_rdf_data)\n",
        "\n",
        "    # Create the animation frames\n",
        "    frames = [go.Frame(\n",
        "        data=[go.Scatter(x=rdf['x'], y=rdf['y'], mode='lines', name='g(r)')],\n",
        "        name=str(rdf['original_frame']),\n",
        "        layout=go.Layout(title_text=f\"Animated RDF - Original Frame {rdf['original_frame']}\")\n",
        "    ) for rdf in valid_rdf_data]\n",
        "\n",
        "    # Create the slider steps\n",
        "    slider_steps = [dict(\n",
        "        method=\"animate\",\n",
        "        args=[[str(rdf['original_frame'])],\n",
        "              {\"frame\": {\"duration\": frame_duration, \"redraw\": True}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}],\n",
        "        label=str(rdf['original_frame'])\n",
        "    ) for rdf in valid_rdf_data]\n",
        "\n",
        "    # Define the plot layout\n",
        "    initial_data = valid_rdf_data[0]\n",
        "    layout = go.Layout(\n",
        "        xaxis=dict(range=[0, cutoff_radius], title=\"Distance (r) [Å]\"),\n",
        "        yaxis=dict(range=[0, max_y_value * 1.1], title=\"g(r)\"),\n",
        "        title=f\"Animated RDF - Original Frame {initial_data['original_frame']}\",\n",
        "        updatemenus=[dict(\n",
        "            type=\"buttons\",\n",
        "            buttons=[\n",
        "                dict(label=\"Play\", method=\"animate\", args=[None, {\"frame\": {\"duration\": frame_duration, \"redraw\": True}, \"fromcurrent\": True, \"transition\": {\"duration\": 0}}]),\n",
        "                dict(label=\"Pause\", method=\"animate\", args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\", \"transition\": {\"duration\": 0}}])\n",
        "            ]\n",
        "        )],\n",
        "        sliders=[dict(\n",
        "            active=0,\n",
        "            currentvalue={\"prefix\": \"Frame: \"},\n",
        "            pad={\"t\": 50},\n",
        "            steps=slider_steps\n",
        "        )]\n",
        "    )\n",
        "\n",
        "    # Assemble the final figure\n",
        "    fig = go.Figure(\n",
        "        data=[go.Scatter(x=initial_data['x'], y=initial_data['y'], mode='lines', name='g(r)')],\n",
        "        layout=layout,\n",
        "        frames=frames\n",
        "    )\n",
        "\n",
        "    # --- Save and return the figure ---\n",
        "    fig.write_html(output_filename)\n",
        "    print(f\"Animation successfully saved as '{output_filename}'\")\n",
        "    return fig\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP6UtBRZwTzb"
      },
      "source": [
        "# RDF animation from mlip method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "J2cCd1bHu1cj",
        "outputId": "5fe8de35-7dfd-4a28-8281-17b95ab2edc5"
      },
      "outputs": [],
      "source": [
        "## faster version : small trajectory\n",
        "if __name__ == '__main__':\n",
        "    # Define the path to your file here\n",
        "    colab_file_path = '/content/drive/MyDrive/A_lammps_n2p2_calculation/dump_equil_small_for_students.lammpstrj'\n",
        "\n",
        "    # Call the function with the desired parameters\n",
        "    my_rdf_figure = generate_rdf_animation(\n",
        "        file_path=colab_file_path,\n",
        "        output_filename='rdf_animation_Al.html',\n",
        "        cutoff_radius=8.0,\n",
        "        number_of_bins=200\n",
        "    )\n",
        "\n",
        "    # If you wish, you can display the figure directly in the notebook after creating it\n",
        "    if my_rdf_figure:\n",
        "        my_rdf_figure.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TYupGmySH49"
      },
      "outputs": [],
      "source": [
        "# --- EXAMPLE USAGE IN GOOGLE COLAB ---\n",
        "if __name__ == '__main__':\n",
        "    # Define the path to your file here\n",
        "    colab_file_path = '/content/drive/MyDrive/A_lammps_n2p2_calculation/dump_equil_200structures.lammpstrj'\n",
        "\n",
        "    # Call the function with the desired parameters\n",
        "    my_rdf_figure = generate_rdf_animation(\n",
        "        file_path=colab_file_path,\n",
        "        output_filename='rdf_animation_Al.html',\n",
        "        cutoff_radius=8.0,\n",
        "        number_of_bins=200\n",
        "    )\n",
        "\n",
        "    # If you wish, you can display the figure directly in the notebook after creating it\n",
        "    if my_rdf_figure:\n",
        "        my_rdf_figure.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LGoQG_dxBlt"
      },
      "source": [
        "# RDF animation from EAM classical potential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ3P0rC8qOr-"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Define the path to your file here\n",
        "    colab_file_path = '/content/drive/MyDrive/A_data_summer_school_25/traj_ramp_100K_to_2000K.xyz'\n",
        "\n",
        "    # Call the function with the desired parameters\n",
        "    my_rdf_figure = generate_rdf_animation(\n",
        "        file_path=colab_file_path,\n",
        "        output_filename='rdf_animation_Al.html',\n",
        "        cutoff_radius=8.0,\n",
        "        number_of_bins=200\n",
        "    )\n",
        "\n",
        "    # If you wish, you can display the figure directly in the notebook after creating it\n",
        "    if my_rdf_figure:\n",
        "        my_rdf_figure.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
